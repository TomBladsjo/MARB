{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25665bdc-b306-4858-9ceb-a0e3ca5e794c",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "\n",
    "The original NL sequences used to build the MARB dataset were retrieved from the enTenTen corpus using SketchEngine's *Concordance* tool. Since the tool operates with a fixed context window rather than sentence boundaries, and since the matches are returned as a CSV file with *left context*, *match* and *right context* as separate fields, this script was used to clean the matches before continuing with the dataset creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83502d10-51ab-4fb5-b912-efcba112ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bc052e-5263-40c7-baa7-2806754b2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ententen_dir = '/srv/data/gussodato/thesis/ententen/'\n",
    "\n",
    "a_person_path = os.path.join(ententen_dir, 'concordance_preloaded_ententen21_tt31_20240226154708.csv')\n",
    "a_woman_path = os.path.join(ententen_dir, 'concordance_preloaded_ententen21_tt31_20240226154516.csv')\n",
    "a_man_path = os.path.join(ententen_dir, 'concordance_preloaded_ententen21_tt31_20240226154231.csv')\n",
    "\n",
    "paths = [(a_person_path, 'person'), (a_woman_path, 'woman'), (a_man_path, 'man')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c527cd-dff8-4a66-bd85-ffba2b6a204c",
   "metadata": {},
   "source": [
    "### Concordance search results\n",
    "The first four lines of the concordance files are information about the search settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ea1e30-4bc4-454d-99f9-b229ad626c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search term: person\n",
      "--------------------\n",
      "﻿\"corpus\",\"preloaded/ententen21_tt31\"\n",
      "\"subcorpus\",\"-\"\n",
      "\"concordance size\",\"10000\"\n",
      "\"query\",\"Query:[lc=\"\"\\ba\"\"] [lc=\"\"person\\b\"\"];Random sample:10000\"\n",
      "\n",
      "Search term: woman\n",
      "--------------------\n",
      "﻿\"corpus\",\"preloaded/ententen21_tt31\"\n",
      "\"subcorpus\",\"-\"\n",
      "\"concordance size\",\"10000\"\n",
      "\"query\",\"Query:[lc=\"\"\\ba\"\"] [lc=\"\"woman\\b\"\"];Random sample:10000\"\n",
      "\n",
      "Search term: man\n",
      "--------------------\n",
      "﻿\"corpus\",\"preloaded/ententen21_tt31\"\n",
      "\"subcorpus\",\"-\"\n",
      "\"concordance size\",\"10000\"\n",
      "\"query\",\"Query:[lc=\"\"\\ba\"\"] [lc=\"\"man\\b\"\"];Random sample:10000\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path, person in paths:\n",
    "    print(fr'Search term: {person}')\n",
    "    print('-'*20)\n",
    "    with open(path) as f:\n",
    "        for _ in range(4):\n",
    "            print(next(f).strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d0a00-7ba5-4d2f-b118-2a37aa02ec7a",
   "metadata": {},
   "source": [
    "The rest is a CSV file with *Left*, *KWIC* (Key Word In Context) and *Right* as separate fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d499f7b-6561-4465-85e1-c04fa86c97cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Left</th>\n",
       "      <th>KWIC</th>\n",
       "      <th>Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm.org</td>\n",
       "      <td>reduces stress and produces more neurological ...</td>\n",
       "      <td>a person</td>\n",
       "      <td>with seizure disorder could, of course, enjoy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hnn.us</td>\n",
       "      <td>period I study, everyone''s well-being was at ...</td>\n",
       "      <td>a person</td>\n",
       "      <td>was the colonist or the colonized, the enslave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hnn.us</td>\n",
       "      <td>is bought up of so-called liberals wanting to ...</td>\n",
       "      <td>a person</td>\n",
       "      <td>might kill 6-20 other people. &lt;/s&gt;&lt;s&gt; By defin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uh.edu</td>\n",
       "      <td>&lt;s&gt; When you know how to search your mind, ide...</td>\n",
       "      <td>a person</td>\n",
       "      <td>who can look at a beehive and change the world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hnn.us</td>\n",
       "      <td>on grounds of uncollegiality. &lt;/s&gt;&lt;s&gt; And thes...</td>\n",
       "      <td>a person</td>\n",
       "      <td>who at times tends to interpret differences ov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reference                                               Left      KWIC  \\\n",
       "0    tm.org  reduces stress and produces more neurological ...  a person   \n",
       "1    hnn.us  period I study, everyone''s well-being was at ...  a person   \n",
       "2    hnn.us  is bought up of so-called liberals wanting to ...  a person   \n",
       "3    uh.edu  <s> When you know how to search your mind, ide...  a person   \n",
       "4    hnn.us  on grounds of uncollegiality. </s><s> And thes...  a person   \n",
       "\n",
       "                                               Right  \n",
       "0  with seizure disorder could, of course, enjoy ...  \n",
       "1  was the colonist or the colonized, the enslave...  \n",
       "2  might kill 6-20 other people. </s><s> By defin...  \n",
       "3  who can look at a beehive and change the world...  \n",
       "4  who at times tends to interpret differences ov...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_example = pd.read_csv(a_person_path, header=4)\n",
    "raw_data_example.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5e7a3-16f5-4368-be8f-8c96f5e44443",
   "metadata": {},
   "source": [
    "We need to remove surplus context and join the search expression with its left and right context. The result will be saved to a textfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cda52f-aacd-4880-9c29-390dace7f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_matches(csv_path, person_word, savedir='/srv/data/gussodato/thesis/ententen/'):\n",
    "    \"\"\"\n",
    "    Remove context outside of sentence boundaries. if sentence boundary is not included in context, \n",
    "    split at furthest comma. Write result to file.\n",
    "    \"\"\"\n",
    "    print(f'Cleaning \"{person_word}\" samples in {csv_path}...')\n",
    "    df = pd.read_csv(csv_path, header=4)\n",
    "    leftcontexts = [line.split('>')[-1] if '>' in line else ' '.join(line.split(',')[1:]) for line in list(df['Left'])]\n",
    "    matches = list(df['KWIC'])\n",
    "    rightcontexts = [line.split('<')[0] if '<' in line else ' '.join(line.split(',')[:-1]) for line in list(df['Right'])]\n",
    "    \n",
    "    clean_sents = [' '.join(row) for row in zip(leftcontexts, matches, rightcontexts)]\n",
    "    \n",
    "    filename = os.path.join(savedir, person_word+'_clean.txt')\n",
    "    print(f'Writing to {filename}...')\n",
    "    with open(filename, 'w') as f:\n",
    "        for line in clean_sents:\n",
    "            f.write(line+'\\n')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb49d9c-75b3-479e-8c85-c7941b180d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning \"person\" samples in /srv/data/gussodato/thesis/ententen/concordance_preloaded_ententen21_tt31_20240226154708.csv...\n",
      "Writing to /srv/data/gussodato/thesis/ententen/person_clean.txt...\n",
      "Done!\n",
      "Cleaning \"woman\" samples in /srv/data/gussodato/thesis/ententen/concordance_preloaded_ententen21_tt31_20240226154516.csv...\n",
      "Writing to /srv/data/gussodato/thesis/ententen/woman_clean.txt...\n",
      "Done!\n",
      "Cleaning \"man\" samples in /srv/data/gussodato/thesis/ententen/concordance_preloaded_ententen21_tt31_20240226154231.csv...\n",
      "Writing to /srv/data/gussodato/thesis/ententen/man_clean.txt...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for path, person_word in [(a_person_path, 'person'), (a_woman_path, 'woman'), (a_man_path, 'man')]:\n",
    "    clean_matches(path, person_word, ententen_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454add98-6b7a-4601-9f2e-38fb885a6c5c",
   "metadata": {},
   "source": [
    "### Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
